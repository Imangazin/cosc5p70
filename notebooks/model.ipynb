{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gideonoludeyi/cosc5p70/blob/main/notebooks/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1af94d-17df-4b5b-9403-c4e3ea4ea2cc",
      "metadata": {
        "id": "dc1af94d-17df-4b5b-9403-c4e3ea4ea2cc"
      },
      "source": [
        "### Data: Predict Students' Dropout and Academic Success\n",
        "\n",
        "@misc{predict_students'_dropout_and_academic_success_697,\n",
        "  author       = {Realinho, Valentim, Vieira Martins, Mónica, Machado, Jorge, and Baptista, Luís},\n",
        "  title        = {{Predict Students' Dropout and Academic Success}},\n",
        "  year         = {2021},\n",
        "  howpublished = {UCI Machine Learning Repository},\n",
        "  note         = {{DOI}: [https://doi.org/10.24432/C5MC89](https://doi.org/10.24432/C5MC89)}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e4192320-b495-4ae6-b151-8ea7f5e54a78",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "e4192320-b495-4ae6-b151-8ea7f5e54a78",
        "outputId": "49884558-a75b-4bec-a4d3-a3098beca7bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install \"ucimlrepo\" \"pandas\" \"numpy\" \"matplotlib\" \"torch\" \"scikit-learn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2f30f272-815b-4a55-bfa1-f243fd003096",
      "metadata": {
        "id": "2f30f272-815b-4a55-bfa1-f243fd003096"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b14e7db7-6d45-4526-8969-b3a7749dc921",
      "metadata": {
        "id": "b14e7db7-6d45-4526-8969-b3a7749dc921"
      },
      "outputs": [],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset - https://archive.ics.uci.edu/dataset/697\n",
        "repo = fetch_ucirepo(id=697)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = repo.data.features\n",
        "\n",
        "#X_norm = nn.functional.normalize(torch.from_numpy(X.values), p=2, dim=1)\n",
        "mean = X.mean(axis=0)\n",
        "std = X.std(axis=0)\n",
        "X = (X - mean) / std\n",
        "y = repo.data.targets['Target']\n",
        "\n",
        "#X = pd.DataFrame(X_norm.numpy(), columns=X.columns)\n",
        "\n",
        "# metadata\n",
        "# print(repo.metadata)\n",
        "\n",
        "# variable information\n",
        "# print(repo.variables)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([repo.data.features, repo.data.targets['Target']], axis=1)\n",
        "df.to_csv('data.csv', index=True)"
      ],
      "metadata": {
        "id": "B3C0eGnOQV1S"
      },
      "id": "B3C0eGnOQV1S",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f91cf371-1bc9-4356-84d6-d8ceb4e88696",
      "metadata": {
        "id": "f91cf371-1bc9-4356-84d6-d8ceb4e88696"
      },
      "outputs": [],
      "source": [
        "# Fixing the random seed to guarantee deterministic results\n",
        "def set_seed(seed):\n",
        "    import os\n",
        "    import random\n",
        "    import numpy as np\n",
        "    import torch\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed = 123456789\n",
        "set_seed(seed)\n",
        "rng = torch.Generator().manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3dd56486-5312-47b1-9189-2f858ca980ab",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dd56486-5312-47b1-9189-2f858ca980ab",
        "outputId": "476c2ea7-4831-401a-b52b-a00743eea3da",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4424 entries, 0 to 4423\n",
            "Data columns (total 36 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   Marital Status                                  4424 non-null   float64\n",
            " 1   Application mode                                4424 non-null   float64\n",
            " 2   Application order                               4424 non-null   float64\n",
            " 3   Course                                          4424 non-null   float64\n",
            " 4   Daytime/evening attendance                      4424 non-null   float64\n",
            " 5   Previous qualification                          4424 non-null   float64\n",
            " 6   Previous qualification (grade)                  4424 non-null   float64\n",
            " 7   Nacionality                                     4424 non-null   float64\n",
            " 8   Mother's qualification                          4424 non-null   float64\n",
            " 9   Father's qualification                          4424 non-null   float64\n",
            " 10  Mother's occupation                             4424 non-null   float64\n",
            " 11  Father's occupation                             4424 non-null   float64\n",
            " 12  Admission grade                                 4424 non-null   float64\n",
            " 13  Displaced                                       4424 non-null   float64\n",
            " 14  Educational special needs                       4424 non-null   float64\n",
            " 15  Debtor                                          4424 non-null   float64\n",
            " 16  Tuition fees up to date                         4424 non-null   float64\n",
            " 17  Gender                                          4424 non-null   float64\n",
            " 18  Scholarship holder                              4424 non-null   float64\n",
            " 19  Age at enrollment                               4424 non-null   float64\n",
            " 20  International                                   4424 non-null   float64\n",
            " 21  Curricular units 1st sem (credited)             4424 non-null   float64\n",
            " 22  Curricular units 1st sem (enrolled)             4424 non-null   float64\n",
            " 23  Curricular units 1st sem (evaluations)          4424 non-null   float64\n",
            " 24  Curricular units 1st sem (approved)             4424 non-null   float64\n",
            " 25  Curricular units 1st sem (grade)                4424 non-null   float64\n",
            " 26  Curricular units 1st sem (without evaluations)  4424 non-null   float64\n",
            " 27  Curricular units 2nd sem (credited)             4424 non-null   float64\n",
            " 28  Curricular units 2nd sem (enrolled)             4424 non-null   float64\n",
            " 29  Curricular units 2nd sem (evaluations)          4424 non-null   float64\n",
            " 30  Curricular units 2nd sem (approved)             4424 non-null   float64\n",
            " 31  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
            " 32  Curricular units 2nd sem (without evaluations)  4424 non-null   float64\n",
            " 33  Unemployment rate                               4424 non-null   float64\n",
            " 34  Inflation rate                                  4424 non-null   float64\n",
            " 35  GDP                                             4424 non-null   float64\n",
            "dtypes: float64(36)\n",
            "memory usage: 1.2 MB\n"
          ]
        }
      ],
      "source": [
        "X.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = X.drop(columns=['Gender', 'Nacionality'])"
      ],
      "metadata": {
        "id": "_ni_7zvxJMMM"
      },
      "id": "_ni_7zvxJMMM",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7i_IvNaJLr6",
        "outputId": "07bccd39-dbd6-4a77-9641-232e58978bfc"
      },
      "id": "W7i_IvNaJLr6",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4424 entries, 0 to 4423\n",
            "Data columns (total 34 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   Marital Status                                  4424 non-null   float64\n",
            " 1   Application mode                                4424 non-null   float64\n",
            " 2   Application order                               4424 non-null   float64\n",
            " 3   Course                                          4424 non-null   float64\n",
            " 4   Daytime/evening attendance                      4424 non-null   float64\n",
            " 5   Previous qualification                          4424 non-null   float64\n",
            " 6   Previous qualification (grade)                  4424 non-null   float64\n",
            " 7   Mother's qualification                          4424 non-null   float64\n",
            " 8   Father's qualification                          4424 non-null   float64\n",
            " 9   Mother's occupation                             4424 non-null   float64\n",
            " 10  Father's occupation                             4424 non-null   float64\n",
            " 11  Admission grade                                 4424 non-null   float64\n",
            " 12  Displaced                                       4424 non-null   float64\n",
            " 13  Educational special needs                       4424 non-null   float64\n",
            " 14  Debtor                                          4424 non-null   float64\n",
            " 15  Tuition fees up to date                         4424 non-null   float64\n",
            " 16  Scholarship holder                              4424 non-null   float64\n",
            " 17  Age at enrollment                               4424 non-null   float64\n",
            " 18  International                                   4424 non-null   float64\n",
            " 19  Curricular units 1st sem (credited)             4424 non-null   float64\n",
            " 20  Curricular units 1st sem (enrolled)             4424 non-null   float64\n",
            " 21  Curricular units 1st sem (evaluations)          4424 non-null   float64\n",
            " 22  Curricular units 1st sem (approved)             4424 non-null   float64\n",
            " 23  Curricular units 1st sem (grade)                4424 non-null   float64\n",
            " 24  Curricular units 1st sem (without evaluations)  4424 non-null   float64\n",
            " 25  Curricular units 2nd sem (credited)             4424 non-null   float64\n",
            " 26  Curricular units 2nd sem (enrolled)             4424 non-null   float64\n",
            " 27  Curricular units 2nd sem (evaluations)          4424 non-null   float64\n",
            " 28  Curricular units 2nd sem (approved)             4424 non-null   float64\n",
            " 29  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
            " 30  Curricular units 2nd sem (without evaluations)  4424 non-null   float64\n",
            " 31  Unemployment rate                               4424 non-null   float64\n",
            " 32  Inflation rate                                  4424 non-null   float64\n",
            " 33  GDP                                             4424 non-null   float64\n",
            "dtypes: float64(34)\n",
            "memory usage: 1.1 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "E_yt27zWxCuu",
        "outputId": "1a72b1ec-fb2c-4004-a4c5-eba9a649076b"
      },
      "id": "E_yt27zWxCuu",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Marital Status  Application mode  Application order        Course  \\\n",
              "count    4.424000e+03      4.424000e+03       4.424000e+03  4.424000e+03   \n",
              "mean    -8.030546e-17     -1.220643e-16      -1.397315e-16  2.577805e-16   \n",
              "std      1.000000e+00      1.000000e+00       1.000000e+00  1.000000e+00   \n",
              "min     -2.947954e-01     -1.010546e+00      -1.315160e+00 -4.275919e+00   \n",
              "25%     -2.947954e-01     -1.010546e+00      -5.540051e-01  1.106615e-01   \n",
              "50%     -2.947954e-01     -9.545943e-02      -5.540051e-01  1.848050e-01   \n",
              "75%     -2.947954e-01      1.162785e+00       2.071497e-01  3.389071e-01   \n",
              "max      7.959476e+00      2.192257e+00       5.535234e+00  5.497072e-01   \n",
              "\n",
              "       Daytime/evening attendance  Previous qualification  \\\n",
              "count                4.424000e+03            4.424000e+03   \n",
              "mean                 5.781993e-17           -3.212219e-17   \n",
              "std                  1.000000e+00            1.000000e+00   \n",
              "min                 -2.856147e+00           -3.501909e-01   \n",
              "25%                  3.500429e-01           -3.501909e-01   \n",
              "50%                  3.500429e-01           -3.501909e-01   \n",
              "75%                  3.500429e-01           -3.501909e-01   \n",
              "max                  3.500429e-01            3.760769e+00   \n",
              "\n",
              "       Previous qualification (grade)  Mother's qualification  \\\n",
              "count                    4.424000e+03            4.424000e+03   \n",
              "mean                    -3.517379e-16           -1.188521e-16   \n",
              "std                      1.000000e+00            1.000000e+00   \n",
              "min                     -2.852015e+00           -1.189625e+00   \n",
              "25%                     -5.772765e-01           -1.125535e+00   \n",
              "50%                      3.690279e-02           -3.601411e-02   \n",
              "75%                      5.600925e-01            1.117596e+00   \n",
              "max                      4.351323e+00            1.566223e+00   \n",
              "\n",
              "       Father's qualification  Mother's occupation  ...  \\\n",
              "count            4.424000e+03         4.424000e+03  ...   \n",
              "mean             1.284887e-17        -1.365193e-17  ...   \n",
              "std              1.000000e+00         1.000000e+00  ...   \n",
              "min             -1.386637e+00        -4.148986e-01  ...   \n",
              "25%             -1.256285e+00        -2.634881e-01  ...   \n",
              "50%             -2.134715e-01        -2.256355e-01  ...   \n",
              "75%              9.596937e-01        -7.422501e-02  ...   \n",
              "max              1.415925e+00         6.928509e+00  ...   \n",
              "\n",
              "       Curricular units 1st sem (without evaluations)  \\\n",
              "count                                    4.424000e+03   \n",
              "mean                                    -2.007637e-17   \n",
              "std                                      1.000000e+00   \n",
              "min                                     -1.992505e-01   \n",
              "25%                                     -1.992505e-01   \n",
              "50%                                     -1.992505e-01   \n",
              "75%                                     -1.992505e-01   \n",
              "max                                      1.716990e+01   \n",
              "\n",
              "       Curricular units 2nd sem (credited)  \\\n",
              "count                         4.424000e+03   \n",
              "mean                         -3.212219e-18   \n",
              "std                           1.000000e+00   \n",
              "min                          -2.824104e-01   \n",
              "25%                          -2.824104e-01   \n",
              "50%                          -2.824104e-01   \n",
              "75%                          -2.824104e-01   \n",
              "max                           9.620922e+00   \n",
              "\n",
              "       Curricular units 2nd sem (enrolled)  \\\n",
              "count                         4.424000e+03   \n",
              "mean                          1.702476e-16   \n",
              "std                           1.000000e+00   \n",
              "min                          -2.838016e+00   \n",
              "25%                          -5.610977e-01   \n",
              "50%                          -1.057141e-01   \n",
              "75%                           3.496696e-01   \n",
              "max                           7.635807e+00   \n",
              "\n",
              "       Curricular units 2nd sem (evaluations)  \\\n",
              "count                            4.424000e+03   \n",
              "mean                            -5.460771e-17   \n",
              "std                              1.000000e+00   \n",
              "min                             -2.042399e+00   \n",
              "25%                             -5.226233e-01   \n",
              "50%                             -1.603139e-02   \n",
              "75%                              4.905605e-01   \n",
              "max                              6.316367e+00   \n",
              "\n",
              "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "count                         4.424000e+03                      4.424000e+03   \n",
              "mean                         -1.156399e-16                      4.818328e-17   \n",
              "std                           1.000000e+00                      1.000000e+00   \n",
              "min                          -1.471361e+00                     -1.963267e+00   \n",
              "25%                          -8.079587e-01                      9.975311e-02   \n",
              "50%                           1.871441e-01                      3.780209e-01   \n",
              "75%                           5.188450e-01                      5.955176e-01   \n",
              "max                           5.162658e+00                      1.600754e+00   \n",
              "\n",
              "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "count                                    4.424000e+03       4.424000e+03   \n",
              "mean                                     8.030546e-19      -7.227492e-17   \n",
              "std                                      1.000000e+00       1.000000e+00   \n",
              "min                                     -1.994184e-01      -1.488875e+00   \n",
              "25%                                     -1.994184e-01      -8.131610e-01   \n",
              "50%                                     -1.994184e-01      -1.749870e-01   \n",
              "75%                                     -1.994184e-01       8.761230e-01   \n",
              "max                                      1.572047e+01       1.739535e+00   \n",
              "\n",
              "       Inflation rate           GDP  \n",
              "count    4.424000e+03  4.424000e+03  \n",
              "mean     1.349132e-16  3.212219e-18  \n",
              "std      1.000000e+00  1.000000e+00  \n",
              "min     -1.466705e+00 -1.789464e+00  \n",
              "25%     -6.711664e-01 -7.497873e-01  \n",
              "50%      1.243724e-01  1.401058e-01  \n",
              "75%      9.922329e-01  7.877013e-01  \n",
              "max      1.787772e+00  1.545432e+00  \n",
              "\n",
              "[8 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19750bfb-06fd-4bd3-a951-02d92da70e51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 1st sem (without evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>...</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "      <td>4.424000e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-8.030546e-17</td>\n",
              "      <td>-1.220643e-16</td>\n",
              "      <td>-1.397315e-16</td>\n",
              "      <td>2.577805e-16</td>\n",
              "      <td>5.781993e-17</td>\n",
              "      <td>-3.212219e-17</td>\n",
              "      <td>-3.517379e-16</td>\n",
              "      <td>-1.188521e-16</td>\n",
              "      <td>1.284887e-17</td>\n",
              "      <td>-1.365193e-17</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.007637e-17</td>\n",
              "      <td>-3.212219e-18</td>\n",
              "      <td>1.702476e-16</td>\n",
              "      <td>-5.460771e-17</td>\n",
              "      <td>-1.156399e-16</td>\n",
              "      <td>4.818328e-17</td>\n",
              "      <td>8.030546e-19</td>\n",
              "      <td>-7.227492e-17</td>\n",
              "      <td>1.349132e-16</td>\n",
              "      <td>3.212219e-18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-2.947954e-01</td>\n",
              "      <td>-1.010546e+00</td>\n",
              "      <td>-1.315160e+00</td>\n",
              "      <td>-4.275919e+00</td>\n",
              "      <td>-2.856147e+00</td>\n",
              "      <td>-3.501909e-01</td>\n",
              "      <td>-2.852015e+00</td>\n",
              "      <td>-1.189625e+00</td>\n",
              "      <td>-1.386637e+00</td>\n",
              "      <td>-4.148986e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.992505e-01</td>\n",
              "      <td>-2.824104e-01</td>\n",
              "      <td>-2.838016e+00</td>\n",
              "      <td>-2.042399e+00</td>\n",
              "      <td>-1.471361e+00</td>\n",
              "      <td>-1.963267e+00</td>\n",
              "      <td>-1.994184e-01</td>\n",
              "      <td>-1.488875e+00</td>\n",
              "      <td>-1.466705e+00</td>\n",
              "      <td>-1.789464e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-2.947954e-01</td>\n",
              "      <td>-1.010546e+00</td>\n",
              "      <td>-5.540051e-01</td>\n",
              "      <td>1.106615e-01</td>\n",
              "      <td>3.500429e-01</td>\n",
              "      <td>-3.501909e-01</td>\n",
              "      <td>-5.772765e-01</td>\n",
              "      <td>-1.125535e+00</td>\n",
              "      <td>-1.256285e+00</td>\n",
              "      <td>-2.634881e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.992505e-01</td>\n",
              "      <td>-2.824104e-01</td>\n",
              "      <td>-5.610977e-01</td>\n",
              "      <td>-5.226233e-01</td>\n",
              "      <td>-8.079587e-01</td>\n",
              "      <td>9.975311e-02</td>\n",
              "      <td>-1.994184e-01</td>\n",
              "      <td>-8.131610e-01</td>\n",
              "      <td>-6.711664e-01</td>\n",
              "      <td>-7.497873e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.947954e-01</td>\n",
              "      <td>-9.545943e-02</td>\n",
              "      <td>-5.540051e-01</td>\n",
              "      <td>1.848050e-01</td>\n",
              "      <td>3.500429e-01</td>\n",
              "      <td>-3.501909e-01</td>\n",
              "      <td>3.690279e-02</td>\n",
              "      <td>-3.601411e-02</td>\n",
              "      <td>-2.134715e-01</td>\n",
              "      <td>-2.256355e-01</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.992505e-01</td>\n",
              "      <td>-2.824104e-01</td>\n",
              "      <td>-1.057141e-01</td>\n",
              "      <td>-1.603139e-02</td>\n",
              "      <td>1.871441e-01</td>\n",
              "      <td>3.780209e-01</td>\n",
              "      <td>-1.994184e-01</td>\n",
              "      <td>-1.749870e-01</td>\n",
              "      <td>1.243724e-01</td>\n",
              "      <td>1.401058e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-2.947954e-01</td>\n",
              "      <td>1.162785e+00</td>\n",
              "      <td>2.071497e-01</td>\n",
              "      <td>3.389071e-01</td>\n",
              "      <td>3.500429e-01</td>\n",
              "      <td>-3.501909e-01</td>\n",
              "      <td>5.600925e-01</td>\n",
              "      <td>1.117596e+00</td>\n",
              "      <td>9.596937e-01</td>\n",
              "      <td>-7.422501e-02</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.992505e-01</td>\n",
              "      <td>-2.824104e-01</td>\n",
              "      <td>3.496696e-01</td>\n",
              "      <td>4.905605e-01</td>\n",
              "      <td>5.188450e-01</td>\n",
              "      <td>5.955176e-01</td>\n",
              "      <td>-1.994184e-01</td>\n",
              "      <td>8.761230e-01</td>\n",
              "      <td>9.922329e-01</td>\n",
              "      <td>7.877013e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.959476e+00</td>\n",
              "      <td>2.192257e+00</td>\n",
              "      <td>5.535234e+00</td>\n",
              "      <td>5.497072e-01</td>\n",
              "      <td>3.500429e-01</td>\n",
              "      <td>3.760769e+00</td>\n",
              "      <td>4.351323e+00</td>\n",
              "      <td>1.566223e+00</td>\n",
              "      <td>1.415925e+00</td>\n",
              "      <td>6.928509e+00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.716990e+01</td>\n",
              "      <td>9.620922e+00</td>\n",
              "      <td>7.635807e+00</td>\n",
              "      <td>6.316367e+00</td>\n",
              "      <td>5.162658e+00</td>\n",
              "      <td>1.600754e+00</td>\n",
              "      <td>1.572047e+01</td>\n",
              "      <td>1.739535e+00</td>\n",
              "      <td>1.787772e+00</td>\n",
              "      <td>1.545432e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19750bfb-06fd-4bd3-a951-02d92da70e51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-19750bfb-06fd-4bd3-a951-02d92da70e51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-19750bfb-06fd-4bd3-a951-02d92da70e51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5dd2e03c-d269-426d-af7e-41053584fc13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5dd2e03c-d269-426d-af7e-41053584fc13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5dd2e03c-d269-426d-af7e-41053584fc13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There are three labels: 'Dropout', 'Enrolled', and 'Graduate'\n",
        "# But there are way more instances of 'Graduate'.\n",
        "#   could it lead to bias in the model?\n",
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Qr6EM8h8xMFt",
        "outputId": "4a02c789-bf64-422c-d41a-4fc7bfa0e371"
      },
      "id": "Qr6EM8h8xMFt",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Target\n",
              "Graduate    2209\n",
              "Dropout     1421\n",
              "Enrolled     794\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Graduate</th>\n",
              "      <td>2209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dropout</th>\n",
              "      <td>1421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Enrolled</th>\n",
              "      <td>794</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e7df060c-a05c-4ba0-911a-097f65fa38c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "e7df060c-a05c-4ba0-911a-097f65fa38c4",
        "outputId": "11bbf7b8-daa5-4e21-879c-5b6bfce21fa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Marital Status  Application mode  Application order    Course  \\\n",
              "2374       -0.294795          1.162785          -0.554005  0.132468   \n",
              "4189       -0.294795          1.334364          -0.554005  0.192559   \n",
              "831        -0.294795          1.162785          -0.554005  0.184805   \n",
              "410        -0.294795         -1.010546           0.207150  0.311770   \n",
              "3983       -0.294795         -0.095459          -0.554005  0.184805   \n",
              "3000       -0.294795          1.162785          -0.554005  0.311770   \n",
              "2760       -0.294795          1.162785          -0.554005  0.311770   \n",
              "2660        1.356059          1.162785          -0.554005  0.549707   \n",
              "1661       -0.294795         -1.010546           0.207150  0.110662   \n",
              "839        -0.294795         -1.010546          -0.554005  0.140707   \n",
              "\n",
              "      Daytime/evening attendance  Previous qualification  \\\n",
              "2374                    0.350043               -0.350191   \n",
              "4189                    0.350043               -0.350191   \n",
              "831                     0.350043                0.432849   \n",
              "410                     0.350043               -0.350191   \n",
              "3983                    0.350043               -0.350191   \n",
              "3000                    0.350043               -0.350191   \n",
              "2760                    0.350043               -0.056551   \n",
              "2660                   -2.856147               -0.350191   \n",
              "1661                    0.350043               -0.350191   \n",
              "839                     0.350043               -0.350191   \n",
              "\n",
              "      Previous qualification (grade)  Mother's qualification  \\\n",
              "2374                        1.318339               -0.036014   \n",
              "4189                        1.621637                1.181686   \n",
              "831                         0.036903                0.925328   \n",
              "410                         0.332619               -0.036014   \n",
              "3983                        0.939216                1.181686   \n",
              "3000                        1.166689               -1.061446   \n",
              "2760                        1.318339               -1.061446   \n",
              "2660                       -0.956399               -0.036014   \n",
              "1661                        1.849111               -1.061446   \n",
              "839                        -0.577276                1.181686   \n",
              "\n",
              "      Father's qualification  Mother's occupation  ...  \\\n",
              "2374               -0.213472            -0.074225  ...   \n",
              "4189                0.959694            -0.377046  ...   \n",
              "831                 0.764166            -0.414899  ...   \n",
              "410                -0.213472            -0.149930  ...   \n",
              "3983                1.024870            -0.074225  ...   \n",
              "3000               -0.213472            -0.339193  ...   \n",
              "2760                1.024870            -0.301341  ...   \n",
              "2660                0.959694            -0.301341  ...   \n",
              "1661               -1.256285            -0.225635  ...   \n",
              "839                -1.386637            -0.301341  ...   \n",
              "\n",
              "      Curricular units 1st sem (without evaluations)  \\\n",
              "2374                                        1.248178   \n",
              "4189                                       -0.199251   \n",
              "831                                        -0.199251   \n",
              "410                                        -0.199251   \n",
              "3983                                       -0.199251   \n",
              "3000                                       -0.199251   \n",
              "2760                                       -0.199251   \n",
              "2660                                       -0.199251   \n",
              "1661                                       -0.199251   \n",
              "839                                        -0.199251   \n",
              "\n",
              "      Curricular units 2nd sem (credited)  \\\n",
              "2374                            -0.282410   \n",
              "4189                             1.281274   \n",
              "831                             -0.282410   \n",
              "410                             -0.282410   \n",
              "3983                            -0.282410   \n",
              "3000                            -0.282410   \n",
              "2760                             0.760046   \n",
              "2660                            -0.282410   \n",
              "1661                            -0.282410   \n",
              "839                             -0.282410   \n",
              "\n",
              "      Curricular units 2nd sem (enrolled)  \\\n",
              "2374                            -0.561098   \n",
              "4189                             2.626588   \n",
              "831                             -0.561098   \n",
              "410                              0.805053   \n",
              "3983                            -0.105714   \n",
              "3000                             0.805053   \n",
              "2760                             0.805053   \n",
              "2660                            -0.561098   \n",
              "1661                            -0.105714   \n",
              "839                             -0.561098   \n",
              "\n",
              "      Curricular units 2nd sem (evaluations)  \\\n",
              "2374                                0.237265   \n",
              "4189                                3.023520   \n",
              "831                                 0.490561   \n",
              "410                                -0.016031   \n",
              "3983                               -0.522623   \n",
              "3000                                0.997152   \n",
              "2760                                0.490561   \n",
              "2660                                0.743856   \n",
              "1661                               -0.522623   \n",
              "839                                -0.269327   \n",
              "\n",
              "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "2374                            -0.476258                          0.339639   \n",
              "4189                             1.182247                          0.339639   \n",
              "831                             -1.471361                         -1.963267   \n",
              "410                              0.850546                          0.849020   \n",
              "3983                             0.518845                          0.563533   \n",
              "3000                             0.850546                          0.476717   \n",
              "2760                             0.850546                          0.590320   \n",
              "2660                            -0.144557                          0.211700   \n",
              "1661                             0.518845                          1.043305   \n",
              "839                              0.187144                          0.416403   \n",
              "\n",
              "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "2374                                       -0.199418          -0.813161   \n",
              "4189                                       -0.199418          -0.813161   \n",
              "831                                        -0.199418          -1.488875   \n",
              "410                                        -0.199418          -0.287606   \n",
              "3983                                       -0.199418           0.313028   \n",
              "3000                                       -0.199418           0.425647   \n",
              "2760                                       -0.199418          -0.174987   \n",
              "2660                                       -0.199418           0.876123   \n",
              "1661                                       -0.199418           0.876123   \n",
              "839                                        -0.199418          -0.813161   \n",
              "\n",
              "      Inflation rate       GDP  \n",
              "2374       -1.466705 -1.375356  \n",
              "4189       -1.466705 -1.375356  \n",
              "831         0.992233  0.140106  \n",
              "410         0.124372  0.765674  \n",
              "3983       -0.526523  0.787701  \n",
              "3000        1.787772 -0.749787  \n",
              "2760       -0.454201  0.889026  \n",
              "2660       -1.105097  0.347160  \n",
              "1661       -1.105097  0.347160  \n",
              "839        -1.466705 -1.375356  \n",
              "\n",
              "[10 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a5dbb4d8-6b5b-4d64-a042-3f03da2025e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 1st sem (without evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2374</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.132468</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>1.318339</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>-0.213472</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>...</td>\n",
              "      <td>1.248178</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.561098</td>\n",
              "      <td>0.237265</td>\n",
              "      <td>-0.476258</td>\n",
              "      <td>0.339639</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.813161</td>\n",
              "      <td>-1.466705</td>\n",
              "      <td>-1.375356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4189</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.334364</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.192559</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>1.621637</td>\n",
              "      <td>1.181686</td>\n",
              "      <td>0.959694</td>\n",
              "      <td>-0.377046</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>1.281274</td>\n",
              "      <td>2.626588</td>\n",
              "      <td>3.023520</td>\n",
              "      <td>1.182247</td>\n",
              "      <td>0.339639</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.813161</td>\n",
              "      <td>-1.466705</td>\n",
              "      <td>-1.375356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>831</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.184805</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>0.432849</td>\n",
              "      <td>0.036903</td>\n",
              "      <td>0.925328</td>\n",
              "      <td>0.764166</td>\n",
              "      <td>-0.414899</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.561098</td>\n",
              "      <td>0.490561</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-1.488875</td>\n",
              "      <td>0.992233</td>\n",
              "      <td>0.140106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>0.207150</td>\n",
              "      <td>0.311770</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>0.332619</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>-0.213472</td>\n",
              "      <td>-0.149930</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>0.805053</td>\n",
              "      <td>-0.016031</td>\n",
              "      <td>0.850546</td>\n",
              "      <td>0.849020</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.287606</td>\n",
              "      <td>0.124372</td>\n",
              "      <td>0.765674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3983</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-0.095459</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.184805</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>0.939216</td>\n",
              "      <td>1.181686</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-0.522623</td>\n",
              "      <td>0.518845</td>\n",
              "      <td>0.563533</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>0.313028</td>\n",
              "      <td>-0.526523</td>\n",
              "      <td>0.787701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3000</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.311770</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>1.166689</td>\n",
              "      <td>-1.061446</td>\n",
              "      <td>-0.213472</td>\n",
              "      <td>-0.339193</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>0.805053</td>\n",
              "      <td>0.997152</td>\n",
              "      <td>0.850546</td>\n",
              "      <td>0.476717</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>0.425647</td>\n",
              "      <td>1.787772</td>\n",
              "      <td>-0.749787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2760</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.311770</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.056551</td>\n",
              "      <td>1.318339</td>\n",
              "      <td>-1.061446</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>-0.301341</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>0.760046</td>\n",
              "      <td>0.805053</td>\n",
              "      <td>0.490561</td>\n",
              "      <td>0.850546</td>\n",
              "      <td>0.590320</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.174987</td>\n",
              "      <td>-0.454201</td>\n",
              "      <td>0.889026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2660</th>\n",
              "      <td>1.356059</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.549707</td>\n",
              "      <td>-2.856147</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-0.956399</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>0.959694</td>\n",
              "      <td>-0.301341</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.561098</td>\n",
              "      <td>0.743856</td>\n",
              "      <td>-0.144557</td>\n",
              "      <td>0.211700</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>0.876123</td>\n",
              "      <td>-1.105097</td>\n",
              "      <td>0.347160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1661</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>0.207150</td>\n",
              "      <td>0.110662</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>1.849111</td>\n",
              "      <td>-1.061446</td>\n",
              "      <td>-1.256285</td>\n",
              "      <td>-0.225635</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-0.522623</td>\n",
              "      <td>0.518845</td>\n",
              "      <td>1.043305</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>0.876123</td>\n",
              "      <td>-1.105097</td>\n",
              "      <td>0.347160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>839</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.140707</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-0.577276</td>\n",
              "      <td>1.181686</td>\n",
              "      <td>-1.386637</td>\n",
              "      <td>-0.301341</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.199251</td>\n",
              "      <td>-0.282410</td>\n",
              "      <td>-0.561098</td>\n",
              "      <td>-0.269327</td>\n",
              "      <td>0.187144</td>\n",
              "      <td>0.416403</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.813161</td>\n",
              "      <td>-1.466705</td>\n",
              "      <td>-1.375356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a5dbb4d8-6b5b-4d64-a042-3f03da2025e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a5dbb4d8-6b5b-4d64-a042-3f03da2025e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a5dbb4d8-6b5b-4d64-a042-3f03da2025e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bf658bd8-ab1d-4bf4-a2bf-cabfceb925c7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bf658bd8-ab1d-4bf4-a2bf-cabfceb925c7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bf658bd8-ab1d-4bf4-a2bf-cabfceb925c7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Samples from the data\n",
        "X.sample(10, random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d87a92f0-3750-4a03-ab6b-fa9fc070950f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87a92f0-3750-4a03-ab6b-fa9fc070950f",
        "outputId": "caf89b78-2f44-48b9-d675-93090e6d1cc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 3539 (0.80)\n",
            "Test  set size: 885  (0.20)\n"
          ]
        }
      ],
      "source": [
        "# Data splitting - training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, shuffle=True, random_state=seed)\n",
        "\n",
        "print(f\"Train set size: {len(y_train)} ({len(y_train) / len(y):.2f})\")\n",
        "print(f\"Test  set size: {len(y_test)}  ({len(y_test) / len(y):.2f})\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_to_index(label):\n",
        "  map = {'Dropout': 0, 'Enrolled': 1, 'Graduate': 2}\n",
        "  return map[label]\n",
        "\n",
        "def index_to_label(index):\n",
        "  map = {0: 'Dropout', 1: 'Enrolled', 2: 'Graduate'}\n",
        "  return map[index]"
      ],
      "metadata": {
        "id": "hcSq2C_eBuEv"
      },
      "id": "hcSq2C_eBuEv",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train.apply(label_to_index)\n",
        "y_test = y_test.apply(label_to_index)"
      ],
      "metadata": {
        "id": "Hpg0mn6pCAiM"
      },
      "id": "Hpg0mn6pCAiM",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e4d86295-989e-4079-a4dc-27ecdcf23f62",
      "metadata": {
        "id": "e4d86295-989e-4079-a4dc-27ecdcf23f62"
      },
      "outputs": [],
      "source": [
        "class SupervisedDataset(Dataset):\n",
        "    def __init__(self, X, y, transform=None):\n",
        "        self.X = np.asarray(X)\n",
        "        self.y = np.asarray(y)\n",
        "        self.transform = transform # function to process the features\n",
        "        #self.target_transform = target_transform # function to process the label\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.X[index]\n",
        "        label = self.y[index]\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "        #if self.target_transform is not None:\n",
        "        #    label = self.target_transform(label)\n",
        "        return features, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "36e80863-3520-424d-92e8-777f2ae0d810",
      "metadata": {
        "id": "36e80863-3520-424d-92e8-777f2ae0d810"
      },
      "outputs": [],
      "source": [
        "def train_step(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    batch_size = dataloader.batch_size\n",
        "    # Set the model to training mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Convert X and y to float tensors to match model requirements\n",
        "        X, y = X.clone().detach().float(), y.clone().detach().long()\n",
        "\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % (batch_size // 4) == 0:\n",
        "            loss = loss.item()\n",
        "            current = batch * dataloader.batch_size + len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_step(dataloader, model, loss_fn):\n",
        "    # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
        "    # Unnecessary in this situation but added for best practices\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n accuracy: {(100*correct):>0.1f}%, avg.loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "caf18e47-e8db-466f-9679-830702328f41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caf18e47-e8db-466f-9679-830702328f41",
        "outputId": "ebc0801e-8280-429a-918b-6c45b2c1e026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dimensions: 34\n",
            "Sequential(\n",
            "  (0): Linear(in_features=34, out_features=64, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=64, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Neural network architecture (36 x 16 x 3)\n",
        "\n",
        "input_dimensions = np.shape(X_train)[1]\n",
        "\n",
        "print(f\"Input dimensions: {input_dimensions}\")\n",
        "\n",
        "model = nn.Sequential(\n",
        "    # Input Layer is implicit\n",
        "    nn.Linear(input_dimensions, 64, dtype=torch.float32), # Hidden Layer\n",
        "    nn.ReLU(), # Hidden Layer: activation\n",
        "    nn.Linear(64, 3, dtype=torch.float32), # Output Layer\n",
        "    #nn.Softmax(dim=1), # Output Layer: activation\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0001\n",
        "momentum = 0.9\n",
        "epochs = 100\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "qYeY-pk1CFfl"
      },
      "id": "qYeY-pk1CFfl",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_train = np.unique(y_train)\n",
        "loss_weights = compute_class_weight('balanced', classes=classes_train, y=y_train)\n",
        "loss_weights = torch.tensor(loss_weights, dtype=torch.float32)\n",
        "print(f\"Classes:      {classes_train}\")\n",
        "print(f\"Loss Weights: {loss_weights}\")\n",
        "\n",
        "# Loss function\n",
        "#  assign weights labels due to imbalance in labels\n",
        "#  e.g., there are more 'Graduate' instances than 'Enrolled' and 'Dropout'\n",
        "#        so 'Graduate' label is assigned a lower weight in term of loss\n",
        "loss_fn = nn.CrossEntropyLoss(weight=loss_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDDKHLPFywn8",
        "outputId": "7f4505cb-93af-44d3-f0fa-94074ce9ddb7"
      },
      "id": "NDDKHLPFywn8",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes:      [0 1 2]\n",
            "Loss Weights: tensor([1.0375, 1.8577, 0.6676])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum) # Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "daXTDIoYCODb"
      },
      "id": "daXTDIoYCODb",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "72aae356-f66d-4268-849a-bb58aeab2b4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72aae356-f66d-4268-849a-bb58aeab2b4f",
        "outputId": "7b21b3da-ac26-475f-a8c6-b2b470138166",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.136433  [   64/ 3539]\n",
            "loss: 1.089554  [ 1088/ 3539]\n",
            "loss: 1.100806  [ 2112/ 3539]\n",
            "loss: 1.099540  [ 3136/ 3539]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-ab482a69be3a>:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X, y = torch.tensor(X, dtype=torch.float32), torch.tensor(y, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " accuracy: 36.2%, avg.loss: 1.093598 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.084967  [   64/ 3539]\n",
            "loss: 1.092157  [ 1088/ 3539]\n",
            "loss: 1.067300  [ 2112/ 3539]\n",
            "loss: 1.081509  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 39.4%, avg.loss: 1.085404 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.110769  [   64/ 3539]\n",
            "loss: 1.063002  [ 1088/ 3539]\n",
            "loss: 1.068312  [ 2112/ 3539]\n",
            "loss: 1.092758  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 42.8%, avg.loss: 1.077442 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.050394  [   64/ 3539]\n",
            "loss: 1.047885  [ 1088/ 3539]\n",
            "loss: 1.061451  [ 2112/ 3539]\n",
            "loss: 1.066537  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 44.9%, avg.loss: 1.069353 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.040785  [   64/ 3539]\n",
            "loss: 1.062785  [ 1088/ 3539]\n",
            "loss: 1.036796  [ 2112/ 3539]\n",
            "loss: 1.081972  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 47.6%, avg.loss: 1.061666 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.121390  [   64/ 3539]\n",
            "loss: 1.058277  [ 1088/ 3539]\n",
            "loss: 1.068322  [ 2112/ 3539]\n",
            "loss: 1.072771  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 48.9%, avg.loss: 1.056349 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.045985  [   64/ 3539]\n",
            "loss: 1.076095  [ 1088/ 3539]\n",
            "loss: 1.078541  [ 2112/ 3539]\n",
            "loss: 1.014491  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 49.5%, avg.loss: 1.047895 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.048962  [   64/ 3539]\n",
            "loss: 1.030778  [ 1088/ 3539]\n",
            "loss: 1.057172  [ 2112/ 3539]\n",
            "loss: 1.028569  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 50.4%, avg.loss: 1.041613 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.044102  [   64/ 3539]\n",
            "loss: 1.057398  [ 1088/ 3539]\n",
            "loss: 1.016639  [ 2112/ 3539]\n",
            "loss: 1.071066  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 51.9%, avg.loss: 1.034893 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.029501  [   64/ 3539]\n",
            "loss: 1.037659  [ 1088/ 3539]\n",
            "loss: 1.038171  [ 2112/ 3539]\n",
            "loss: 0.961105  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 53.7%, avg.loss: 1.029033 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.079117  [   64/ 3539]\n",
            "loss: 1.005456  [ 1088/ 3539]\n",
            "loss: 0.993141  [ 2112/ 3539]\n",
            "loss: 1.017530  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 55.4%, avg.loss: 1.022925 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.037109  [   64/ 3539]\n",
            "loss: 0.984325  [ 1088/ 3539]\n",
            "loss: 1.022117  [ 2112/ 3539]\n",
            "loss: 1.004597  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 55.7%, avg.loss: 1.017178 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.026173  [   64/ 3539]\n",
            "loss: 1.035258  [ 1088/ 3539]\n",
            "loss: 0.940478  [ 2112/ 3539]\n",
            "loss: 1.013379  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 56.0%, avg.loss: 1.011585 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.033660  [   64/ 3539]\n",
            "loss: 1.025005  [ 1088/ 3539]\n",
            "loss: 1.015857  [ 2112/ 3539]\n",
            "loss: 1.056658  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 57.4%, avg.loss: 1.005363 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 0.932637  [   64/ 3539]\n",
            "loss: 0.985927  [ 1088/ 3539]\n",
            "loss: 1.020268  [ 2112/ 3539]\n",
            "loss: 1.038748  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 57.7%, avg.loss: 1.000015 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.009577  [   64/ 3539]\n",
            "loss: 0.978084  [ 1088/ 3539]\n",
            "loss: 0.974501  [ 2112/ 3539]\n",
            "loss: 1.012707  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 58.6%, avg.loss: 0.995135 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.002228  [   64/ 3539]\n",
            "loss: 0.985385  [ 1088/ 3539]\n",
            "loss: 0.990398  [ 2112/ 3539]\n",
            "loss: 0.984602  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 60.1%, avg.loss: 0.990433 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 0.991857  [   64/ 3539]\n",
            "loss: 1.025276  [ 1088/ 3539]\n",
            "loss: 0.959884  [ 2112/ 3539]\n",
            "loss: 1.014629  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 61.1%, avg.loss: 0.984313 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 0.979301  [   64/ 3539]\n",
            "loss: 0.981604  [ 1088/ 3539]\n",
            "loss: 0.966042  [ 2112/ 3539]\n",
            "loss: 1.013890  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 61.8%, avg.loss: 0.978968 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.037368  [   64/ 3539]\n",
            "loss: 0.974676  [ 1088/ 3539]\n",
            "loss: 0.991236  [ 2112/ 3539]\n",
            "loss: 0.939645  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 62.7%, avg.loss: 0.973067 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 0.979328  [   64/ 3539]\n",
            "loss: 0.931274  [ 1088/ 3539]\n",
            "loss: 0.976034  [ 2112/ 3539]\n",
            "loss: 0.906436  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 63.5%, avg.loss: 0.968838 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 0.921502  [   64/ 3539]\n",
            "loss: 0.957690  [ 1088/ 3539]\n",
            "loss: 1.011771  [ 2112/ 3539]\n",
            "loss: 0.990529  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 63.8%, avg.loss: 0.964692 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 0.946571  [   64/ 3539]\n",
            "loss: 0.999751  [ 1088/ 3539]\n",
            "loss: 1.010348  [ 2112/ 3539]\n",
            "loss: 0.970240  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 64.3%, avg.loss: 0.959218 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 0.965483  [   64/ 3539]\n",
            "loss: 0.974235  [ 1088/ 3539]\n",
            "loss: 0.939062  [ 2112/ 3539]\n",
            "loss: 0.969769  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 64.3%, avg.loss: 0.954757 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.025259  [   64/ 3539]\n",
            "loss: 0.929451  [ 1088/ 3539]\n",
            "loss: 0.918525  [ 2112/ 3539]\n",
            "loss: 0.953396  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 64.6%, avg.loss: 0.949883 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 0.995568  [   64/ 3539]\n",
            "loss: 0.964734  [ 1088/ 3539]\n",
            "loss: 0.956892  [ 2112/ 3539]\n",
            "loss: 0.962454  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 65.2%, avg.loss: 0.944855 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 0.917444  [   64/ 3539]\n",
            "loss: 0.918973  [ 1088/ 3539]\n",
            "loss: 0.927243  [ 2112/ 3539]\n",
            "loss: 0.998907  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 65.2%, avg.loss: 0.940943 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 0.917699  [   64/ 3539]\n",
            "loss: 0.942826  [ 1088/ 3539]\n",
            "loss: 0.949937  [ 2112/ 3539]\n",
            "loss: 0.954931  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 65.4%, avg.loss: 0.937212 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 0.903544  [   64/ 3539]\n",
            "loss: 0.901033  [ 1088/ 3539]\n",
            "loss: 0.892783  [ 2112/ 3539]\n",
            "loss: 0.935972  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 66.0%, avg.loss: 0.931266 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 0.959531  [   64/ 3539]\n",
            "loss: 0.909543  [ 1088/ 3539]\n",
            "loss: 1.003414  [ 2112/ 3539]\n",
            "loss: 0.910218  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 66.3%, avg.loss: 0.928040 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 0.955527  [   64/ 3539]\n",
            "loss: 0.944597  [ 1088/ 3539]\n",
            "loss: 0.916767  [ 2112/ 3539]\n",
            "loss: 0.948268  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 66.3%, avg.loss: 0.924280 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 0.943605  [   64/ 3539]\n",
            "loss: 0.914588  [ 1088/ 3539]\n",
            "loss: 0.961686  [ 2112/ 3539]\n",
            "loss: 0.900262  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 66.6%, avg.loss: 0.919898 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 0.926102  [   64/ 3539]\n",
            "loss: 0.949605  [ 1088/ 3539]\n",
            "loss: 0.887303  [ 2112/ 3539]\n",
            "loss: 0.902877  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 66.8%, avg.loss: 0.916285 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 0.912901  [   64/ 3539]\n",
            "loss: 0.866779  [ 1088/ 3539]\n",
            "loss: 0.972792  [ 2112/ 3539]\n",
            "loss: 0.922098  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.1%, avg.loss: 0.912837 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 0.944589  [   64/ 3539]\n",
            "loss: 0.973570  [ 1088/ 3539]\n",
            "loss: 0.915019  [ 2112/ 3539]\n",
            "loss: 0.987667  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.1%, avg.loss: 0.908903 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 0.875584  [   64/ 3539]\n",
            "loss: 0.863209  [ 1088/ 3539]\n",
            "loss: 0.909030  [ 2112/ 3539]\n",
            "loss: 0.852864  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.0%, avg.loss: 0.905506 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 0.925539  [   64/ 3539]\n",
            "loss: 0.994183  [ 1088/ 3539]\n",
            "loss: 0.855545  [ 2112/ 3539]\n",
            "loss: 0.944116  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.0%, avg.loss: 0.902328 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 0.966109  [   64/ 3539]\n",
            "loss: 0.876549  [ 1088/ 3539]\n",
            "loss: 0.933720  [ 2112/ 3539]\n",
            "loss: 0.855293  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.2%, avg.loss: 0.898851 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 0.917842  [   64/ 3539]\n",
            "loss: 0.871789  [ 1088/ 3539]\n",
            "loss: 0.936574  [ 2112/ 3539]\n",
            "loss: 0.936142  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.2%, avg.loss: 0.895686 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 0.907123  [   64/ 3539]\n",
            "loss: 0.911954  [ 1088/ 3539]\n",
            "loss: 0.925602  [ 2112/ 3539]\n",
            "loss: 0.889246  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.3%, avg.loss: 0.891976 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 0.826577  [   64/ 3539]\n",
            "loss: 0.959464  [ 1088/ 3539]\n",
            "loss: 0.790864  [ 2112/ 3539]\n",
            "loss: 0.945065  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.5%, avg.loss: 0.888649 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 0.905300  [   64/ 3539]\n",
            "loss: 0.974685  [ 1088/ 3539]\n",
            "loss: 0.953601  [ 2112/ 3539]\n",
            "loss: 0.973565  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.1%, avg.loss: 0.885239 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.894909  [   64/ 3539]\n",
            "loss: 0.925514  [ 1088/ 3539]\n",
            "loss: 0.893077  [ 2112/ 3539]\n",
            "loss: 0.846956  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.3%, avg.loss: 0.883718 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.988554  [   64/ 3539]\n",
            "loss: 0.809976  [ 1088/ 3539]\n",
            "loss: 0.867610  [ 2112/ 3539]\n",
            "loss: 0.903852  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.5%, avg.loss: 0.879011 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.889881  [   64/ 3539]\n",
            "loss: 0.852340  [ 1088/ 3539]\n",
            "loss: 0.837865  [ 2112/ 3539]\n",
            "loss: 0.833647  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.5%, avg.loss: 0.875622 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.815143  [   64/ 3539]\n",
            "loss: 0.870029  [ 1088/ 3539]\n",
            "loss: 0.760827  [ 2112/ 3539]\n",
            "loss: 0.841324  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.3%, avg.loss: 0.873802 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.861593  [   64/ 3539]\n",
            "loss: 0.770489  [ 1088/ 3539]\n",
            "loss: 0.872820  [ 2112/ 3539]\n",
            "loss: 0.817885  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.6%, avg.loss: 0.869293 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.859220  [   64/ 3539]\n",
            "loss: 0.850418  [ 1088/ 3539]\n",
            "loss: 0.912475  [ 2112/ 3539]\n",
            "loss: 0.879003  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 67.8%, avg.loss: 0.868074 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.926306  [   64/ 3539]\n",
            "loss: 0.871985  [ 1088/ 3539]\n",
            "loss: 0.767082  [ 2112/ 3539]\n",
            "loss: 0.881921  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.1%, avg.loss: 0.863375 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.902640  [   64/ 3539]\n",
            "loss: 0.913089  [ 1088/ 3539]\n",
            "loss: 0.849859  [ 2112/ 3539]\n",
            "loss: 0.945754  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.1%, avg.loss: 0.861639 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.752196  [   64/ 3539]\n",
            "loss: 0.791707  [ 1088/ 3539]\n",
            "loss: 0.912420  [ 2112/ 3539]\n",
            "loss: 0.853785  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.2%, avg.loss: 0.859922 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.822554  [   64/ 3539]\n",
            "loss: 0.869937  [ 1088/ 3539]\n",
            "loss: 0.797078  [ 2112/ 3539]\n",
            "loss: 0.840227  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.4%, avg.loss: 0.853830 \n",
            "\n",
            "Epoch 53\n",
            "-------------------------------\n",
            "loss: 0.818140  [   64/ 3539]\n",
            "loss: 0.812468  [ 1088/ 3539]\n",
            "loss: 0.865942  [ 2112/ 3539]\n",
            "loss: 0.882279  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.4%, avg.loss: 0.852365 \n",
            "\n",
            "Epoch 54\n",
            "-------------------------------\n",
            "loss: 0.888427  [   64/ 3539]\n",
            "loss: 0.771366  [ 1088/ 3539]\n",
            "loss: 0.879723  [ 2112/ 3539]\n",
            "loss: 0.856789  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.851768 \n",
            "\n",
            "Epoch 55\n",
            "-------------------------------\n",
            "loss: 0.920514  [   64/ 3539]\n",
            "loss: 0.793137  [ 1088/ 3539]\n",
            "loss: 0.878230  [ 2112/ 3539]\n",
            "loss: 0.824026  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.850560 \n",
            "\n",
            "Epoch 56\n",
            "-------------------------------\n",
            "loss: 0.850698  [   64/ 3539]\n",
            "loss: 0.934374  [ 1088/ 3539]\n",
            "loss: 0.809467  [ 2112/ 3539]\n",
            "loss: 0.795507  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.846790 \n",
            "\n",
            "Epoch 57\n",
            "-------------------------------\n",
            "loss: 0.855028  [   64/ 3539]\n",
            "loss: 0.794477  [ 1088/ 3539]\n",
            "loss: 0.890535  [ 2112/ 3539]\n",
            "loss: 0.823010  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.842390 \n",
            "\n",
            "Epoch 58\n",
            "-------------------------------\n",
            "loss: 0.860619  [   64/ 3539]\n",
            "loss: 0.818250  [ 1088/ 3539]\n",
            "loss: 0.853791  [ 2112/ 3539]\n",
            "loss: 0.876855  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.842514 \n",
            "\n",
            "Epoch 59\n",
            "-------------------------------\n",
            "loss: 0.793394  [   64/ 3539]\n",
            "loss: 0.837601  [ 1088/ 3539]\n",
            "loss: 0.932666  [ 2112/ 3539]\n",
            "loss: 0.837520  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.839705 \n",
            "\n",
            "Epoch 60\n",
            "-------------------------------\n",
            "loss: 0.845774  [   64/ 3539]\n",
            "loss: 0.763933  [ 1088/ 3539]\n",
            "loss: 0.858614  [ 2112/ 3539]\n",
            "loss: 0.894511  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.5%, avg.loss: 0.838961 \n",
            "\n",
            "Epoch 61\n",
            "-------------------------------\n",
            "loss: 0.760558  [   64/ 3539]\n",
            "loss: 0.830771  [ 1088/ 3539]\n",
            "loss: 0.842371  [ 2112/ 3539]\n",
            "loss: 0.855134  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.8%, avg.loss: 0.834542 \n",
            "\n",
            "Epoch 62\n",
            "-------------------------------\n",
            "loss: 0.868927  [   64/ 3539]\n",
            "loss: 0.782611  [ 1088/ 3539]\n",
            "loss: 0.840381  [ 2112/ 3539]\n",
            "loss: 0.851885  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 68.8%, avg.loss: 0.833215 \n",
            "\n",
            "Epoch 63\n",
            "-------------------------------\n",
            "loss: 0.874555  [   64/ 3539]\n",
            "loss: 0.844790  [ 1088/ 3539]\n",
            "loss: 0.770722  [ 2112/ 3539]\n",
            "loss: 0.935794  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.829259 \n",
            "\n",
            "Epoch 64\n",
            "-------------------------------\n",
            "loss: 0.744124  [   64/ 3539]\n",
            "loss: 0.893519  [ 1088/ 3539]\n",
            "loss: 0.859960  [ 2112/ 3539]\n",
            "loss: 0.833772  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.829578 \n",
            "\n",
            "Epoch 65\n",
            "-------------------------------\n",
            "loss: 0.813977  [   64/ 3539]\n",
            "loss: 0.716171  [ 1088/ 3539]\n",
            "loss: 0.816328  [ 2112/ 3539]\n",
            "loss: 0.821733  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.826505 \n",
            "\n",
            "Epoch 66\n",
            "-------------------------------\n",
            "loss: 0.836948  [   64/ 3539]\n",
            "loss: 0.888689  [ 1088/ 3539]\n",
            "loss: 0.861948  [ 2112/ 3539]\n",
            "loss: 0.869730  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.3%, avg.loss: 0.824271 \n",
            "\n",
            "Epoch 67\n",
            "-------------------------------\n",
            "loss: 0.808413  [   64/ 3539]\n",
            "loss: 0.869115  [ 1088/ 3539]\n",
            "loss: 0.806533  [ 2112/ 3539]\n",
            "loss: 0.765409  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.824320 \n",
            "\n",
            "Epoch 68\n",
            "-------------------------------\n",
            "loss: 0.888163  [   64/ 3539]\n",
            "loss: 0.780141  [ 1088/ 3539]\n",
            "loss: 0.765698  [ 2112/ 3539]\n",
            "loss: 0.880560  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.819833 \n",
            "\n",
            "Epoch 69\n",
            "-------------------------------\n",
            "loss: 0.821624  [   64/ 3539]\n",
            "loss: 0.813727  [ 1088/ 3539]\n",
            "loss: 0.816165  [ 2112/ 3539]\n",
            "loss: 0.820209  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.818262 \n",
            "\n",
            "Epoch 70\n",
            "-------------------------------\n",
            "loss: 0.767803  [   64/ 3539]\n",
            "loss: 0.900230  [ 1088/ 3539]\n",
            "loss: 0.869111  [ 2112/ 3539]\n",
            "loss: 0.828216  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.816634 \n",
            "\n",
            "Epoch 71\n",
            "-------------------------------\n",
            "loss: 0.837714  [   64/ 3539]\n",
            "loss: 0.796086  [ 1088/ 3539]\n",
            "loss: 0.890649  [ 2112/ 3539]\n",
            "loss: 0.809679  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.814055 \n",
            "\n",
            "Epoch 72\n",
            "-------------------------------\n",
            "loss: 0.817551  [   64/ 3539]\n",
            "loss: 0.836240  [ 1088/ 3539]\n",
            "loss: 0.827114  [ 2112/ 3539]\n",
            "loss: 0.930681  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.3%, avg.loss: 0.812324 \n",
            "\n",
            "Epoch 73\n",
            "-------------------------------\n",
            "loss: 0.767098  [   64/ 3539]\n",
            "loss: 0.878329  [ 1088/ 3539]\n",
            "loss: 0.806415  [ 2112/ 3539]\n",
            "loss: 0.892508  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.2%, avg.loss: 0.808054 \n",
            "\n",
            "Epoch 74\n",
            "-------------------------------\n",
            "loss: 0.860029  [   64/ 3539]\n",
            "loss: 0.849357  [ 1088/ 3539]\n",
            "loss: 0.779989  [ 2112/ 3539]\n",
            "loss: 0.806279  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.0%, avg.loss: 0.808578 \n",
            "\n",
            "Epoch 75\n",
            "-------------------------------\n",
            "loss: 0.933689  [   64/ 3539]\n",
            "loss: 0.831206  [ 1088/ 3539]\n",
            "loss: 0.831220  [ 2112/ 3539]\n",
            "loss: 0.760730  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.3%, avg.loss: 0.807916 \n",
            "\n",
            "Epoch 76\n",
            "-------------------------------\n",
            "loss: 0.779936  [   64/ 3539]\n",
            "loss: 0.766688  [ 1088/ 3539]\n",
            "loss: 0.815756  [ 2112/ 3539]\n",
            "loss: 0.843609  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.6%, avg.loss: 0.806967 \n",
            "\n",
            "Epoch 77\n",
            "-------------------------------\n",
            "loss: 0.787626  [   64/ 3539]\n",
            "loss: 0.813581  [ 1088/ 3539]\n",
            "loss: 0.791145  [ 2112/ 3539]\n",
            "loss: 0.776105  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.6%, avg.loss: 0.805788 \n",
            "\n",
            "Epoch 78\n",
            "-------------------------------\n",
            "loss: 0.706822  [   64/ 3539]\n",
            "loss: 0.619640  [ 1088/ 3539]\n",
            "loss: 0.849553  [ 2112/ 3539]\n",
            "loss: 0.756835  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.6%, avg.loss: 0.801324 \n",
            "\n",
            "Epoch 79\n",
            "-------------------------------\n",
            "loss: 0.838455  [   64/ 3539]\n",
            "loss: 0.815525  [ 1088/ 3539]\n",
            "loss: 0.912439  [ 2112/ 3539]\n",
            "loss: 0.740185  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.7%, avg.loss: 0.800188 \n",
            "\n",
            "Epoch 80\n",
            "-------------------------------\n",
            "loss: 0.839519  [   64/ 3539]\n",
            "loss: 0.771151  [ 1088/ 3539]\n",
            "loss: 0.864377  [ 2112/ 3539]\n",
            "loss: 0.849630  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 69.9%, avg.loss: 0.802112 \n",
            "\n",
            "Epoch 81\n",
            "-------------------------------\n",
            "loss: 0.853033  [   64/ 3539]\n",
            "loss: 0.899183  [ 1088/ 3539]\n",
            "loss: 0.749776  [ 2112/ 3539]\n",
            "loss: 0.805260  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.1%, avg.loss: 0.800326 \n",
            "\n",
            "Epoch 82\n",
            "-------------------------------\n",
            "loss: 0.827531  [   64/ 3539]\n",
            "loss: 0.711929  [ 1088/ 3539]\n",
            "loss: 0.821645  [ 2112/ 3539]\n",
            "loss: 0.783593  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.2%, avg.loss: 0.794783 \n",
            "\n",
            "Epoch 83\n",
            "-------------------------------\n",
            "loss: 0.775723  [   64/ 3539]\n",
            "loss: 0.712134  [ 1088/ 3539]\n",
            "loss: 0.825837  [ 2112/ 3539]\n",
            "loss: 0.899970  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.2%, avg.loss: 0.796030 \n",
            "\n",
            "Epoch 84\n",
            "-------------------------------\n",
            "loss: 0.892532  [   64/ 3539]\n",
            "loss: 0.705272  [ 1088/ 3539]\n",
            "loss: 0.845010  [ 2112/ 3539]\n",
            "loss: 0.749347  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.2%, avg.loss: 0.795011 \n",
            "\n",
            "Epoch 85\n",
            "-------------------------------\n",
            "loss: 0.760650  [   64/ 3539]\n",
            "loss: 0.735948  [ 1088/ 3539]\n",
            "loss: 0.798497  [ 2112/ 3539]\n",
            "loss: 0.873031  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.2%, avg.loss: 0.791076 \n",
            "\n",
            "Epoch 86\n",
            "-------------------------------\n",
            "loss: 0.831397  [   64/ 3539]\n",
            "loss: 0.881472  [ 1088/ 3539]\n",
            "loss: 0.689026  [ 2112/ 3539]\n",
            "loss: 0.857144  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.2%, avg.loss: 0.794012 \n",
            "\n",
            "Epoch 87\n",
            "-------------------------------\n",
            "loss: 0.842751  [   64/ 3539]\n",
            "loss: 0.810451  [ 1088/ 3539]\n",
            "loss: 0.754428  [ 2112/ 3539]\n",
            "loss: 0.753293  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.3%, avg.loss: 0.790135 \n",
            "\n",
            "Epoch 88\n",
            "-------------------------------\n",
            "loss: 0.906671  [   64/ 3539]\n",
            "loss: 0.720564  [ 1088/ 3539]\n",
            "loss: 0.805579  [ 2112/ 3539]\n",
            "loss: 0.710130  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.6%, avg.loss: 0.790345 \n",
            "\n",
            "Epoch 89\n",
            "-------------------------------\n",
            "loss: 0.904633  [   64/ 3539]\n",
            "loss: 0.772356  [ 1088/ 3539]\n",
            "loss: 0.797546  [ 2112/ 3539]\n",
            "loss: 0.679652  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 70.8%, avg.loss: 0.786376 \n",
            "\n",
            "Epoch 90\n",
            "-------------------------------\n",
            "loss: 0.793363  [   64/ 3539]\n",
            "loss: 0.812394  [ 1088/ 3539]\n",
            "loss: 0.764978  [ 2112/ 3539]\n",
            "loss: 0.807610  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.1%, avg.loss: 0.786110 \n",
            "\n",
            "Epoch 91\n",
            "-------------------------------\n",
            "loss: 0.685578  [   64/ 3539]\n",
            "loss: 0.855448  [ 1088/ 3539]\n",
            "loss: 0.778711  [ 2112/ 3539]\n",
            "loss: 0.726991  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.2%, avg.loss: 0.786448 \n",
            "\n",
            "Epoch 92\n",
            "-------------------------------\n",
            "loss: 0.785158  [   64/ 3539]\n",
            "loss: 0.690113  [ 1088/ 3539]\n",
            "loss: 0.723956  [ 2112/ 3539]\n",
            "loss: 0.797600  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.4%, avg.loss: 0.784243 \n",
            "\n",
            "Epoch 93\n",
            "-------------------------------\n",
            "loss: 0.744772  [   64/ 3539]\n",
            "loss: 0.761195  [ 1088/ 3539]\n",
            "loss: 0.754795  [ 2112/ 3539]\n",
            "loss: 0.774520  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.5%, avg.loss: 0.783929 \n",
            "\n",
            "Epoch 94\n",
            "-------------------------------\n",
            "loss: 0.840593  [   64/ 3539]\n",
            "loss: 0.771994  [ 1088/ 3539]\n",
            "loss: 0.758670  [ 2112/ 3539]\n",
            "loss: 0.771048  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.4%, avg.loss: 0.782406 \n",
            "\n",
            "Epoch 95\n",
            "-------------------------------\n",
            "loss: 0.855937  [   64/ 3539]\n",
            "loss: 0.789066  [ 1088/ 3539]\n",
            "loss: 0.736381  [ 2112/ 3539]\n",
            "loss: 0.787150  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.4%, avg.loss: 0.782480 \n",
            "\n",
            "Epoch 96\n",
            "-------------------------------\n",
            "loss: 0.818588  [   64/ 3539]\n",
            "loss: 0.759733  [ 1088/ 3539]\n",
            "loss: 0.708472  [ 2112/ 3539]\n",
            "loss: 0.847185  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.4%, avg.loss: 0.782024 \n",
            "\n",
            "Epoch 97\n",
            "-------------------------------\n",
            "loss: 0.773881  [   64/ 3539]\n",
            "loss: 0.823549  [ 1088/ 3539]\n",
            "loss: 0.729457  [ 2112/ 3539]\n",
            "loss: 0.745107  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.3%, avg.loss: 0.780886 \n",
            "\n",
            "Epoch 98\n",
            "-------------------------------\n",
            "loss: 0.790007  [   64/ 3539]\n",
            "loss: 0.853558  [ 1088/ 3539]\n",
            "loss: 0.791107  [ 2112/ 3539]\n",
            "loss: 0.772298  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.3%, avg.loss: 0.777249 \n",
            "\n",
            "Epoch 99\n",
            "-------------------------------\n",
            "loss: 0.628859  [   64/ 3539]\n",
            "loss: 0.795067  [ 1088/ 3539]\n",
            "loss: 0.685146  [ 2112/ 3539]\n",
            "loss: 0.823061  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.2%, avg.loss: 0.776280 \n",
            "\n",
            "Epoch 100\n",
            "-------------------------------\n",
            "loss: 0.715539  [   64/ 3539]\n",
            "loss: 0.700771  [ 1088/ 3539]\n",
            "loss: 0.738376  [ 2112/ 3539]\n",
            "loss: 0.774074  [ 3136/ 3539]\n",
            "Test Error: \n",
            " accuracy: 71.2%, avg.loss: 0.776577 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_data = SupervisedDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True, generator=rng)\n",
        "\n",
        "test_data = SupervisedDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True, generator=rng)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_step(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_step(test_dataloader, model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, X):\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        X = torch.tensor(X, dtype=torch.float32)\n",
        "        pred = model(X)\n",
        "        y_pred = pred.argmax(1)\n",
        "    return np.asarray(y_pred)\n",
        "\n",
        "def get_result(model, features_df, y_true):\n",
        "    X = features_df.values\n",
        "    y_pred = predict(model, X)\n",
        "    result_df = features_df.copy()\n",
        "    result_df['y_true'] = y_true\n",
        "    result_df['y_true'] = result_df['y_true'].apply(index_to_label)\n",
        "    result_df['y_pred'] = y_pred\n",
        "    result_df['y_pred'] = result_df['y_pred'].apply(index_to_label)\n",
        "    return result_df"
      ],
      "metadata": {
        "id": "sQUnbVf6Gdr7"
      },
      "id": "sQUnbVf6Gdr7",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result_df = get_result(model, X_test, y_test.values)\n",
        "test_result_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "_Dh4CMEVP8q-",
        "outputId": "3cf0f38a-b583-45f9-b79d-078f8c10ae98"
      },
      "id": "_Dh4CMEVP8q-",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Marital Status  Application mode  Application order    Course  \\\n",
              "107        -0.294795         -1.010546          -0.554005  0.110662   \n",
              "1319       -0.294795         -0.095459           0.207150  0.482833   \n",
              "3729       -0.294795         -1.010546          -0.554005  0.070924   \n",
              "1572        7.959476          1.162785          -0.554005  0.549707   \n",
              "2684       -0.294795         -0.667389          -0.554005  0.070924   \n",
              "...              ...               ...                ...       ...   \n",
              "2262       -0.294795         -1.010546          -0.554005  0.192559   \n",
              "2689       -0.294795         -0.095459          -0.554005  0.444065   \n",
              "2213       -0.294795         -1.010546          -0.554005  0.184805   \n",
              "2084       -0.294795         -1.010546          -0.554005  0.444065   \n",
              "3346       -0.294795          1.162785          -0.554005  0.311770   \n",
              "\n",
              "      Daytime/evening attendance  Previous qualification  \\\n",
              "107                     0.350043               -0.350191   \n",
              "1319                    0.350043               -0.350191   \n",
              "3729                    0.350043               -0.350191   \n",
              "1572                   -2.856147                0.726489   \n",
              "2684                    0.350043               -0.154431   \n",
              "...                          ...                     ...   \n",
              "2262                    0.350043               -0.350191   \n",
              "2689                    0.350043               -0.350191   \n",
              "2213                    0.350043               -0.350191   \n",
              "2084                    0.350043               -0.350191   \n",
              "3346                    0.350043               -0.350191   \n",
              "\n",
              "      Previous qualification (grade)  Mother's qualification  \\\n",
              "107                        -1.487172               -1.189625   \n",
              "1319                       -0.122329               -1.189625   \n",
              "3729                        0.036903                1.181686   \n",
              "1572                       -0.198153                1.117596   \n",
              "2684                       -0.198153               -1.189625   \n",
              "...                              ...                     ...   \n",
              "2262                        3.441427               -1.125535   \n",
              "2689                        0.939216               -1.189625   \n",
              "2213                        0.560093               -0.036014   \n",
              "2084                       -0.425627               -0.036014   \n",
              "3346                       -0.956399                1.117596   \n",
              "\n",
              "      Father's qualification  Mother's occupation  ...  \\\n",
              "107                -1.386637            -0.263488  ...   \n",
              "1319                1.024870            -0.263488  ...   \n",
              "3729                1.024870            -0.263488  ...   \n",
              "1572                0.959694             2.991837  ...   \n",
              "2684               -0.213472            -0.225635  ...   \n",
              "...                      ...                  ...  ...   \n",
              "2262               -1.386637            -0.339193  ...   \n",
              "2689                1.024870             2.991837  ...   \n",
              "2213                1.024870            -0.074225  ...   \n",
              "2084                0.959694            -0.074225  ...   \n",
              "3346                0.959694            -0.074225  ...   \n",
              "\n",
              "      Curricular units 2nd sem (enrolled)  \\\n",
              "107                             -0.105714   \n",
              "1319                            -0.105714   \n",
              "3729                             2.626588   \n",
              "1572                            -0.561098   \n",
              "2684                            -0.105714   \n",
              "...                                   ...   \n",
              "2262                            -0.105714   \n",
              "2689                            -0.105714   \n",
              "2213                            -0.105714   \n",
              "2084                            -0.105714   \n",
              "3346                             0.349670   \n",
              "\n",
              "      Curricular units 2nd sem (evaluations)  \\\n",
              "107                                 2.263632   \n",
              "1319                               -0.269327   \n",
              "3729                                1.503744   \n",
              "1572                               -0.775919   \n",
              "2684                                0.490561   \n",
              "...                                      ...   \n",
              "2262                               -0.522623   \n",
              "2689                               -2.042399   \n",
              "2213                                0.490561   \n",
              "2084                               -0.522623   \n",
              "3346                               -0.269327   \n",
              "\n",
              "      Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "107                             -0.144557                          0.579525   \n",
              "1319                             0.187144                          0.186112   \n",
              "3729                             2.509051                          0.812030   \n",
              "1572                            -1.471361                         -1.963267   \n",
              "2684                            -1.471361                         -1.963267   \n",
              "...                                   ...                               ...   \n",
              "2262                            -1.471361                         -1.963267   \n",
              "2689                            -1.471361                         -1.963267   \n",
              "2213                            -0.476258                          0.531548   \n",
              "2084                             0.518845                          0.563533   \n",
              "3346                            -1.471361                         -1.963267   \n",
              "\n",
              "      Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "107                                        -0.199418           1.476757   \n",
              "1319                                       -0.199418          -0.287606   \n",
              "3729                                       -0.199418           1.476757   \n",
              "1572                                       -0.199418          -1.488875   \n",
              "2684                                       -0.199418           1.739535   \n",
              "...                                              ...                ...   \n",
              "2262                                       -0.199418           1.476757   \n",
              "2689                                       -0.199418          -0.287606   \n",
              "2213                                       -0.199418           1.739535   \n",
              "2084                                       -0.199418          -0.174987   \n",
              "3346                                       -0.199418           0.876123   \n",
              "\n",
              "      Inflation rate       GDP    y_true    y_pred  \n",
              "107         1.136876 -1.789464   Dropout  Enrolled  \n",
              "1319        0.124372  0.765674  Graduate  Graduate  \n",
              "3729        1.136876 -1.789464  Graduate  Graduate  \n",
              "1572        0.992233  0.140106   Dropout   Dropout  \n",
              "2684       -0.671166 -0.406165   Dropout   Dropout  \n",
              "...              ...       ...       ...       ...  \n",
              "2262        1.136876 -1.789464   Dropout   Dropout  \n",
              "2689        0.124372  0.765674   Dropout   Dropout  \n",
              "2213       -0.671166 -0.406165   Dropout  Graduate  \n",
              "2084       -0.454201  0.889026  Graduate  Graduate  \n",
              "3346       -1.105097  0.347160   Dropout   Dropout  \n",
              "\n",
              "[885 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60e44976-c28f-47d8-a6d0-214bfb885e5e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital Status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Previous qualification (grade)</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>y_true</th>\n",
              "      <th>y_pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.110662</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-1.487172</td>\n",
              "      <td>-1.189625</td>\n",
              "      <td>-1.386637</td>\n",
              "      <td>-0.263488</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>2.263632</td>\n",
              "      <td>-0.144557</td>\n",
              "      <td>0.579525</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>1.476757</td>\n",
              "      <td>1.136876</td>\n",
              "      <td>-1.789464</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Enrolled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1319</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-0.095459</td>\n",
              "      <td>0.207150</td>\n",
              "      <td>0.482833</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-0.122329</td>\n",
              "      <td>-1.189625</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>-0.263488</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-0.269327</td>\n",
              "      <td>0.187144</td>\n",
              "      <td>0.186112</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.287606</td>\n",
              "      <td>0.124372</td>\n",
              "      <td>0.765674</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3729</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.070924</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>0.036903</td>\n",
              "      <td>1.181686</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>-0.263488</td>\n",
              "      <td>...</td>\n",
              "      <td>2.626588</td>\n",
              "      <td>1.503744</td>\n",
              "      <td>2.509051</td>\n",
              "      <td>0.812030</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>1.476757</td>\n",
              "      <td>1.136876</td>\n",
              "      <td>-1.789464</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1572</th>\n",
              "      <td>7.959476</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.549707</td>\n",
              "      <td>-2.856147</td>\n",
              "      <td>0.726489</td>\n",
              "      <td>-0.198153</td>\n",
              "      <td>1.117596</td>\n",
              "      <td>0.959694</td>\n",
              "      <td>2.991837</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.561098</td>\n",
              "      <td>-0.775919</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-1.488875</td>\n",
              "      <td>0.992233</td>\n",
              "      <td>0.140106</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2684</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-0.667389</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.070924</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.154431</td>\n",
              "      <td>-0.198153</td>\n",
              "      <td>-1.189625</td>\n",
              "      <td>-0.213472</td>\n",
              "      <td>-0.225635</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>0.490561</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>1.739535</td>\n",
              "      <td>-0.671166</td>\n",
              "      <td>-0.406165</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2262</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.192559</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>3.441427</td>\n",
              "      <td>-1.125535</td>\n",
              "      <td>-1.386637</td>\n",
              "      <td>-0.339193</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-0.522623</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>1.476757</td>\n",
              "      <td>1.136876</td>\n",
              "      <td>-1.789464</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2689</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-0.095459</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.444065</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>0.939216</td>\n",
              "      <td>-1.189625</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>2.991837</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-2.042399</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.287606</td>\n",
              "      <td>0.124372</td>\n",
              "      <td>0.765674</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2213</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.184805</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>0.560093</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>1.024870</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>0.490561</td>\n",
              "      <td>-0.476258</td>\n",
              "      <td>0.531548</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>1.739535</td>\n",
              "      <td>-0.671166</td>\n",
              "      <td>-0.406165</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>-1.010546</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.444065</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-0.425627</td>\n",
              "      <td>-0.036014</td>\n",
              "      <td>0.959694</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.105714</td>\n",
              "      <td>-0.522623</td>\n",
              "      <td>0.518845</td>\n",
              "      <td>0.563533</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>-0.174987</td>\n",
              "      <td>-0.454201</td>\n",
              "      <td>0.889026</td>\n",
              "      <td>Graduate</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3346</th>\n",
              "      <td>-0.294795</td>\n",
              "      <td>1.162785</td>\n",
              "      <td>-0.554005</td>\n",
              "      <td>0.311770</td>\n",
              "      <td>0.350043</td>\n",
              "      <td>-0.350191</td>\n",
              "      <td>-0.956399</td>\n",
              "      <td>1.117596</td>\n",
              "      <td>0.959694</td>\n",
              "      <td>-0.074225</td>\n",
              "      <td>...</td>\n",
              "      <td>0.349670</td>\n",
              "      <td>-0.269327</td>\n",
              "      <td>-1.471361</td>\n",
              "      <td>-1.963267</td>\n",
              "      <td>-0.199418</td>\n",
              "      <td>0.876123</td>\n",
              "      <td>-1.105097</td>\n",
              "      <td>0.347160</td>\n",
              "      <td>Dropout</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>885 rows × 36 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60e44976-c28f-47d8-a6d0-214bfb885e5e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60e44976-c28f-47d8-a6d0-214bfb885e5e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60e44976-c28f-47d8-a6d0-214bfb885e5e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9c18ab87-7d22-45e7-98a2-d69ac6f5647d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c18ab87-7d22-45e7-98a2-d69ac6f5647d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9c18ab87-7d22-45e7-98a2-d69ac6f5647d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ed91c251-d6dd-4809-9083-88e8e176623a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_result_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ed91c251-d6dd-4809-9083-88e8e176623a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_result_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_result_df"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_result_df.to_csv('test_result.csv', index=True)"
      ],
      "metadata": {
        "id": "nCl9dU9VP9c8"
      },
      "id": "nCl9dU9VP9c8",
      "execution_count": 24,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}